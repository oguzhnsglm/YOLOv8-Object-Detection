{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "346dbd14",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m frames:\n\u001b[0;32m     16\u001b[0m     img_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(frame_folder, f)\n\u001b[1;32m---> 17\u001b[0m     frame \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;66;03m# YOLO tahmin\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     results \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(frame, imgsz\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m640\u001b[39m, conf\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\sagla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ultralytics\\utils\\patches.py:33\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(filename, flags)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimread\u001b[39m(filename: \u001b[38;5;28mstr\u001b[39m, flags: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mIMREAD_COLOR) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[np\u001b[38;5;241m.\u001b[39mndarray]:\n\u001b[0;32m     19\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124;03m    Read an image from a file with multilanguage filename support.\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m        >>> img = imread(\"path/to/image.jpg\", cv2.IMREAD_GRAYSCALE)\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m     file_bytes \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint8\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.tiff\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m     35\u001b[0m         success, frames \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimdecodemulti(file_bytes, cv2\u001b[38;5;241m.\u001b[39mIMREAD_UNCHANGED)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# YOLO modelini yÃ¼kle\n",
    "model = YOLO(\"termal_model.pt\")  # kendi .pt model yolunu yaz\n",
    "\n",
    "# SÄ±nÄ±f isimleri\n",
    "class_map = model.names\n",
    "\n",
    "# Frame klasÃ¶rÃ¼\n",
    "frame_folder = \"termal\"\n",
    "frames = sorted([f for f in os.listdir(frame_folder) if f.endswith('.jpeg')])\n",
    "\n",
    "for f in frames:\n",
    "    img_path = os.path.join(frame_folder, f)\n",
    "    frame = cv2.imread(img_path)\n",
    "\n",
    "    # YOLO tahmin\n",
    "    results = model.predict(frame, imgsz=640, conf=0.25, verbose=False)\n",
    "    preds = results[0].boxes\n",
    "\n",
    "    # KutularÄ± Ã§iz\n",
    "    for box, cls_id in zip(preds.xywh, preds.cls):\n",
    "        xc, yc, bw, bh = box.tolist()\n",
    "        x1, y1 = int(xc - bw/2), int(yc - bh/2)\n",
    "        x2, y2 = int(xc + bw/2), int(yc + bh/2)\n",
    "        label = class_map.get(int(cls_id), str(int(cls_id)))\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (255,140,0), 2)\n",
    "        cv2.putText(frame, label, (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5, (255,140,0), 2, cv2.LINE_AA)\n",
    "\n",
    "    # GÃ¶ster\n",
    "    cv2.imshow(\"Termal YOLO Detection\", frame)\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f89099e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM cevabÄ±: ÃœzgÃ¼nÃ¼m, bu isteÄŸe yardÄ±mcÄ± ol\n",
      "LLM cevabÄ±: ÃœzgÃ¼nÃ¼m, bu gÃ¶rÃ¼ntÃ¼deki\n",
      "\n",
      "==========================\n",
      "ğŸ”« SilahlÄ± kiÅŸi sayÄ±sÄ±   : 0\n",
      "ğŸ§â€â™‚ï¸ SilahsÄ±z kiÅŸi sayÄ±sÄ± : 0\n",
      "==========================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import io\n",
    "import base64\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ğŸ” API anahtarÄ±nÄ± yÃ¼kle\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"âŒ API anahtarÄ± yÃ¼klenemedi.\")\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# ğŸ” GPT-4O ile silah tespiti\n",
    "def llm_detect_weapon_fast(image_crop):\n",
    "    try:\n",
    "        pil_image = Image.fromarray(cv2.cvtColor(image_crop, cv2.COLOR_BGR2RGB))\n",
    "        buffered = io.BytesIO()\n",
    "        pil_image.save(buffered, format=\"JPEG\")\n",
    "        img_base64 = base64.b64encode(buffered.getvalue()).decode()\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": \"Bu kiÅŸide silah var mÄ±? Sadece 'Evet' veya 'HayÄ±r' yaz.\"},\n",
    "                        {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{img_base64}\"}}\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            max_tokens=10,\n",
    "            temperature=0.0\n",
    "        )\n",
    "        cevap = response.choices[0].message.content.strip()\n",
    "        print(f\"LLM cevabÄ±: {cevap}\")  # ğŸ–¨ï¸ AnÄ±nda terminal Ã§Ä±ktÄ±sÄ±\n",
    "        return cevap\n",
    "    except Exception as e:\n",
    "        print(\"LLM hata:\", e)\n",
    "        return \"Bilinmiyor\"\n",
    "\n",
    "# ğŸ“¦ YOLO modeli\n",
    "model = YOLO(\"termal_model.pt\")\n",
    "class_map = model.names\n",
    "\n",
    "# ğŸ“· GÃ¶rseli yÃ¼kle\n",
    "img_path = os.path.join(\"termal\", \"FLIR_video_03383.jpeg\")\n",
    "frame = cv2.imread(img_path)\n",
    "\n",
    "# ğŸ” YOLO tahmini\n",
    "results = model.predict(frame, imgsz=320, conf=0.4, verbose=False)\n",
    "preds = results[0].boxes\n",
    "\n",
    "# ğŸ“Š SayaÃ§lar\n",
    "silahli_sayisi = 0\n",
    "silahsiz_sayisi = 0\n",
    "\n",
    "# ğŸ§â€â™‚ï¸ Her kiÅŸi iÃ§in iÅŸlem yap\n",
    "for box, cls_id in zip(preds.xywh, preds.cls):\n",
    "    xc, yc, bw, bh = box.tolist()\n",
    "    x1, y1 = int(xc - bw / 2), int(yc - bh / 2)\n",
    "    x2, y2 = int(xc + bw / 2), int(yc + bh / 2)\n",
    "    label = class_map.get(int(cls_id), str(int(cls_id)))\n",
    "\n",
    "    if label.lower() == \"person\":\n",
    "        person_crop = frame[y1:y2, x1:x2].copy()\n",
    "        if person_crop.size > 0:\n",
    "            weapon_result = llm_detect_weapon_fast(person_crop)\n",
    "            label += f\" | Silah: {weapon_result}\"\n",
    "\n",
    "            # SayaÃ§ gÃ¼ncelle\n",
    "            if \"Evet\" in weapon_result:\n",
    "                silahli_sayisi += 1\n",
    "            elif \"HayÄ±r\" in weapon_result:\n",
    "                silahsiz_sayisi += 1\n",
    "\n",
    "        # GÃ¶rsel Ã¼zerine yaz\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 140, 0), 2)\n",
    "        cv2.putText(frame, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5, (255, 140, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "# ğŸ“Š Ã–zet Ã§Ä±ktÄ±sÄ±\n",
    "print(\"\\n==========================\")\n",
    "print(f\"ğŸ”« SilahlÄ± kiÅŸi sayÄ±sÄ±   : {silahli_sayisi}\")\n",
    "print(f\"ğŸ§â€â™‚ï¸ SilahsÄ±z kiÅŸi sayÄ±sÄ± : {silahsiz_sayisi}\")\n",
    "print(\"==========================\")\n",
    "\n",
    "# ğŸ–¼ï¸ GÃ¶rseli gÃ¶ster\n",
    "cv2.imshow(\"FLIR Detection - Silah Tespiti\", frame)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "737eafda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM cevabÄ±: HayÄ±r.\n",
      "LLM cevabÄ±: HayÄ±r.\n",
      "\n",
      "==========================\n",
      "ğŸ”« SilahlÄ± kiÅŸi sayÄ±sÄ±   : 0\n",
      "ğŸ§â€â™‚ï¸ SilahsÄ±z kiÅŸi sayÄ±sÄ± : 2\n",
      "==========================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import io\n",
    "import base64\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ğŸ” API anahtarÄ±nÄ± yÃ¼kle\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"âŒ API anahtarÄ± yÃ¼klenemedi.\")\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# ğŸ” GPT-4O ile silah tespiti\n",
    "def llm_detect_weapon_fast(image_crop):\n",
    "    try:\n",
    "        pil_image = Image.fromarray(cv2.cvtColor(image_crop, cv2.COLOR_BGR2RGB))\n",
    "        buffered = io.BytesIO()\n",
    "        pil_image.save(buffered, format=\"JPEG\")\n",
    "        img_base64 = base64.b64encode(buffered.getvalue()).decode()\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": \"Bu kiÅŸinin elinde veya Ã¼zerinde silah olduÄŸu dÃ¼ÅŸÃ¼nÃ¼lebilir mi? Sadece 'Evet' ya da 'HayÄ±r' yaz.\"},\n",
    "                        {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{img_base64}\"}}\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            max_tokens=10,\n",
    "            temperature=0.0\n",
    "        )\n",
    "        cevap = response.choices[0].message.content.strip()\n",
    "        print(f\"LLM cevabÄ±: {cevap}\")\n",
    "        return cevap\n",
    "    except Exception as e:\n",
    "        print(\"LLM hata:\", e)\n",
    "        return \"Bilinmiyor\"\n",
    "\n",
    "# ğŸ“¦ YOLO modeli\n",
    "model = YOLO(\"termal_model.pt\")\n",
    "class_map = model.names\n",
    "\n",
    "# ğŸ“· GÃ¶rseli yÃ¼kle\n",
    "img_path = os.path.join(\"termal\", \"FLIR_video_03901.jpeg\")\n",
    "frame = cv2.imread(img_path)\n",
    "\n",
    "# ğŸ” YOLO tahmini\n",
    "results = model.predict(frame, imgsz=320, conf=0.4, verbose=False)\n",
    "preds = results[0].boxes\n",
    "\n",
    "# ğŸ“Š SayaÃ§lar\n",
    "silahli_sayisi = 0\n",
    "silahsiz_sayisi = 0\n",
    "\n",
    "# ğŸ§â€â™‚ï¸ Her kiÅŸi iÃ§in iÅŸlem yap\n",
    "for box, cls_id in zip(preds.xywh, preds.cls):\n",
    "    xc, yc, bw, bh = box.tolist()\n",
    "    x1, y1 = int(xc - bw / 2), int(yc - bh / 2)\n",
    "    x2, y2 = int(xc + bw / 2), int(yc + bh / 2)\n",
    "    label = class_map.get(int(cls_id), str(int(cls_id)))\n",
    "\n",
    "    if label.lower() == \"person\":\n",
    "        # ğŸ”§ Yeni kÄ±rpma stratejisi: margin + sÄ±nÄ±r kontrolÃ¼\n",
    "        margin = 10\n",
    "        x1_adj = max(0, x1 + margin)\n",
    "        y1_adj = max(0, y1 + margin)\n",
    "        x2_adj = min(frame.shape[1], x2 - margin)\n",
    "        y2_adj = min(frame.shape[0], y2 - margin)\n",
    "\n",
    "        person_crop = frame[y1_adj:y2_adj, x1_adj:x2_adj].copy()\n",
    "\n",
    "        # ğŸ“ Crop boyut kontrolÃ¼\n",
    "        h, w = person_crop.shape[:2]\n",
    "        if h < 50 or w < 50 or h * w > 400 * 400:\n",
    "            print(\"âš ï¸ Uygun olmayan boyutta crop atlandÄ±.\")\n",
    "            continue\n",
    "\n",
    "        # ğŸ” LLM analizi\n",
    "        weapon_result = llm_detect_weapon_fast(person_crop)\n",
    "        label += f\" | Silah: {weapon_result}\"\n",
    "\n",
    "        # SayaÃ§ gÃ¼ncelle\n",
    "        if \"Evet\" in weapon_result:\n",
    "            silahli_sayisi += 1\n",
    "        elif \"HayÄ±r\" in weapon_result:\n",
    "            silahsiz_sayisi += 1\n",
    "\n",
    "        # GÃ¶rsel Ã¼zerine yaz\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 140, 0), 2)\n",
    "        cv2.putText(frame, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5, (255, 140, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "# ğŸ“Š Ã–zet Ã§Ä±ktÄ±sÄ±\n",
    "print(\"\\n==========================\")\n",
    "print(f\"ğŸ”« SilahlÄ± kiÅŸi sayÄ±sÄ±   : {silahli_sayisi}\")\n",
    "print(f\"ğŸ§â€â™‚ï¸ SilahsÄ±z kiÅŸi sayÄ±sÄ± : {silahsiz_sayisi}\")\n",
    "print(\"==========================\")\n",
    "\n",
    "# ğŸ–¼ï¸ GÃ¶rseli gÃ¶ster\n",
    "cv2.imshow(\"FLIR Detection - Silah Tespiti\", frame)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf54741",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
